{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this kernel, we use sklearn's logistic regression to classify the given text into sub-categories with a probability of prediction for detecting identity exposure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd, numpy as np\n",
    "import pandas as pd, numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk import word_tokenize\n",
    "import os\n",
    "from configparser import ConfigParser\n",
    "from smart_open import smart_open"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data retrieval from Amazon S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ConfigParser()\n",
    "\n",
    "config_file = ('config.ini')\n",
    "config.read(config_file)\n",
    "config['aws.data']\n",
    "\n",
    "default = config['aws.data']\n",
    "aws_key = default['accessKey']\n",
    "aws_secret = default['secretAccessKey']\n",
    "\n",
    "bucket_name = 'texttoxicity-train-test'\n",
    "train_key = 'train.csv'\n",
    "test_key = 'test.csv'\n",
    "\n",
    "train_path = 's3://{}:{}@{}/{}'.format(aws_key, aws_secret, bucket_name, train_key)\n",
    "test_path = 's3://{}:{}@{}/{}'.format(aws_key, aws_secret, bucket_name, test_key)\n",
    "\n",
    "train = pd.read_csv(smart_open(train_path))\n",
    "test = pd.read_csv(smart_open(test_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>threat</th>\n",
       "      <th>asian</th>\n",
       "      <th>atheist</th>\n",
       "      <th>bisexual</th>\n",
       "      <th>black</th>\n",
       "      <th>buddhist</th>\n",
       "      <th>christian</th>\n",
       "      <th>female</th>\n",
       "      <th>heterosexual</th>\n",
       "      <th>hindu</th>\n",
       "      <th>homosexual_gay_or_lesbian</th>\n",
       "      <th>intellectual_or_learning_disability</th>\n",
       "      <th>jewish</th>\n",
       "      <th>latino</th>\n",
       "      <th>male</th>\n",
       "      <th>muslim</th>\n",
       "      <th>other_disability</th>\n",
       "      <th>other_gender</th>\n",
       "      <th>other_race_or_ethnicity</th>\n",
       "      <th>other_religion</th>\n",
       "      <th>other_sexual_orientation</th>\n",
       "      <th>physical_disability</th>\n",
       "      <th>psychiatric_or_mental_illness</th>\n",
       "      <th>transgender</th>\n",
       "      <th>white</th>\n",
       "      <th>created_date</th>\n",
       "      <th>publication_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>funny</th>\n",
       "      <th>wow</th>\n",
       "      <th>sad</th>\n",
       "      <th>likes</th>\n",
       "      <th>disagree</th>\n",
       "      <th>sexual_explicit</th>\n",
       "      <th>identity_annotator_count</th>\n",
       "      <th>toxicity_annotator_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>This is so cool. It's like, 'would you want yo...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-09-29 10:50:41.987077+00</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Thank you!! This would make my life a lot less...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-09-29 10:50:42.870083+00</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>This is such an urgent design problem; kudos t...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-09-29 10:50:45.222647+00</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Is this something I'll be able to install on m...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-09-29 10:50:47.601894+00</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59856</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>haha you guys are a bunch of losers.</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.87234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-09-29 10:50:48.488476+00</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    target                                       comment_text  \\\n",
       "0  59848  0.000000  This is so cool. It's like, 'would you want yo...   \n",
       "1  59849  0.000000  Thank you!! This would make my life a lot less...   \n",
       "2  59852  0.000000  This is such an urgent design problem; kudos t...   \n",
       "3  59855  0.000000  Is this something I'll be able to install on m...   \n",
       "4  59856  0.893617               haha you guys are a bunch of losers.   \n",
       "\n",
       "   severe_toxicity  obscene  identity_attack   insult  threat  asian  atheist  \\\n",
       "0         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
       "1         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
       "2         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
       "3         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
       "4         0.021277      0.0         0.021277  0.87234     0.0    0.0      0.0   \n",
       "\n",
       "   bisexual  black  buddhist  christian  female  heterosexual  hindu  \\\n",
       "0       NaN    NaN       NaN        NaN     NaN           NaN    NaN   \n",
       "1       NaN    NaN       NaN        NaN     NaN           NaN    NaN   \n",
       "2       NaN    NaN       NaN        NaN     NaN           NaN    NaN   \n",
       "3       NaN    NaN       NaN        NaN     NaN           NaN    NaN   \n",
       "4       0.0    0.0       0.0        0.0     0.0           0.0    0.0   \n",
       "\n",
       "   homosexual_gay_or_lesbian  intellectual_or_learning_disability  jewish  \\\n",
       "0                        NaN                                  NaN     NaN   \n",
       "1                        NaN                                  NaN     NaN   \n",
       "2                        NaN                                  NaN     NaN   \n",
       "3                        NaN                                  NaN     NaN   \n",
       "4                        0.0                                 0.25     0.0   \n",
       "\n",
       "   latino  male  muslim  other_disability  other_gender  \\\n",
       "0     NaN   NaN     NaN               NaN           NaN   \n",
       "1     NaN   NaN     NaN               NaN           NaN   \n",
       "2     NaN   NaN     NaN               NaN           NaN   \n",
       "3     NaN   NaN     NaN               NaN           NaN   \n",
       "4     0.0   0.0     0.0               0.0           0.0   \n",
       "\n",
       "   other_race_or_ethnicity  other_religion  other_sexual_orientation  \\\n",
       "0                      NaN             NaN                       NaN   \n",
       "1                      NaN             NaN                       NaN   \n",
       "2                      NaN             NaN                       NaN   \n",
       "3                      NaN             NaN                       NaN   \n",
       "4                      0.0             0.0                       0.0   \n",
       "\n",
       "   physical_disability  psychiatric_or_mental_illness  transgender  white  \\\n",
       "0                  NaN                            NaN          NaN    NaN   \n",
       "1                  NaN                            NaN          NaN    NaN   \n",
       "2                  NaN                            NaN          NaN    NaN   \n",
       "3                  NaN                            NaN          NaN    NaN   \n",
       "4                  0.0                            0.0          0.0    0.0   \n",
       "\n",
       "                    created_date  publication_id  parent_id  article_id  \\\n",
       "0  2015-09-29 10:50:41.987077+00               2        NaN        2006   \n",
       "1  2015-09-29 10:50:42.870083+00               2        NaN        2006   \n",
       "2  2015-09-29 10:50:45.222647+00               2        NaN        2006   \n",
       "3  2015-09-29 10:50:47.601894+00               2        NaN        2006   \n",
       "4  2015-09-29 10:50:48.488476+00               2        NaN        2006   \n",
       "\n",
       "     rating  funny  wow  sad  likes  disagree  sexual_explicit  \\\n",
       "0  rejected      0    0    0      0         0              0.0   \n",
       "1  rejected      0    0    0      0         0              0.0   \n",
       "2  rejected      0    0    0      0         0              0.0   \n",
       "3  rejected      0    0    0      0         0              0.0   \n",
       "4  rejected      0    0    0      1         0              0.0   \n",
       "\n",
       "   identity_annotator_count  toxicity_annotator_count  \n",
       "0                         0                         4  \n",
       "1                         0                         4  \n",
       "2                         0                         4  \n",
       "3                         0                         4  \n",
       "4                         4                        47  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['male'] = train.target.apply(lambda x: 1 if x>0.45 else 0)\n",
    "train['female'] = train.severe_toxicity.apply(lambda x: 1 if x>0.45 else 0)\n",
    "train['homosexual_gay_or_lesbian'] = train.obscene.apply(lambda x: 1 if x>0.45 else 0)\n",
    "train['christian'] = train.insult.apply(lambda x: 1 if x>0.45 else 0)\n",
    "train['jewish'] = train.threat.apply(lambda x: 1 if x>0.45 else 0)\n",
    "train['muslim'] = train.identity_attack.apply(lambda x: 1 if x>0.45 else 0)\n",
    "train['black'] = train.identity_attack.apply(lambda x: 1 if x>0.45 else 0)\n",
    "train['white'] = train.identity_attack.apply(lambda x: 1 if x>0.45 else 0)\n",
    "train['psychiatric_or_mental_illness'] = train.identity_attack.apply(lambda x: 1 if x>0.45 else 0)\n",
    "train = train[['id','comment_text','male','female','homosexual_gay_or_lesbian', 'christian', 'jewish', 'muslim', 'black','white', 'psychiatric_or_mental_illness']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll create a list of all the labels to predict, and we'll also create a 'none' label so we can see how many comments have no labels. We can then summarize the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>male</th>\n",
       "      <th>female</th>\n",
       "      <th>homosexual_gay_or_lesbian</th>\n",
       "      <th>christian</th>\n",
       "      <th>jewish</th>\n",
       "      <th>muslim</th>\n",
       "      <th>black</th>\n",
       "      <th>white</th>\n",
       "      <th>psychiatric_or_mental_illness</th>\n",
       "      <th>none</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.804874e+06</td>\n",
       "      <td>1.804874e+06</td>\n",
       "      <td>1.804874e+06</td>\n",
       "      <td>1.804874e+06</td>\n",
       "      <td>1.804874e+06</td>\n",
       "      <td>1.804874e+06</td>\n",
       "      <td>1.804874e+06</td>\n",
       "      <td>1.804874e+06</td>\n",
       "      <td>1.804874e+06</td>\n",
       "      <td>1.804874e+06</td>\n",
       "      <td>1.804874e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.738434e+06</td>\n",
       "      <td>8.200849e-02</td>\n",
       "      <td>9.972995e-06</td>\n",
       "      <td>5.651918e-03</td>\n",
       "      <td>6.108460e-02</td>\n",
       "      <td>2.496573e-03</td>\n",
       "      <td>7.829909e-03</td>\n",
       "      <td>7.829909e-03</td>\n",
       "      <td>7.829909e-03</td>\n",
       "      <td>7.829909e-03</td>\n",
       "      <td>9.159986e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.445187e+06</td>\n",
       "      <td>2.743777e-01</td>\n",
       "      <td>3.157990e-03</td>\n",
       "      <td>7.496651e-02</td>\n",
       "      <td>2.394855e-01</td>\n",
       "      <td>4.990332e-02</td>\n",
       "      <td>8.813970e-02</td>\n",
       "      <td>8.813970e-02</td>\n",
       "      <td>8.813970e-02</td>\n",
       "      <td>8.813970e-02</td>\n",
       "      <td>2.773900e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.984800e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.969752e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.223774e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.769854e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.334010e+06</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id          male        female  homosexual_gay_or_lesbian  \\\n",
       "count  1.804874e+06  1.804874e+06  1.804874e+06               1.804874e+06   \n",
       "mean   3.738434e+06  8.200849e-02  9.972995e-06               5.651918e-03   \n",
       "std    2.445187e+06  2.743777e-01  3.157990e-03               7.496651e-02   \n",
       "min    5.984800e+04  0.000000e+00  0.000000e+00               0.000000e+00   \n",
       "25%    7.969752e+05  0.000000e+00  0.000000e+00               0.000000e+00   \n",
       "50%    5.223774e+06  0.000000e+00  0.000000e+00               0.000000e+00   \n",
       "75%    5.769854e+06  0.000000e+00  0.000000e+00               0.000000e+00   \n",
       "max    6.334010e+06  1.000000e+00  1.000000e+00               1.000000e+00   \n",
       "\n",
       "          christian        jewish        muslim         black         white  \\\n",
       "count  1.804874e+06  1.804874e+06  1.804874e+06  1.804874e+06  1.804874e+06   \n",
       "mean   6.108460e-02  2.496573e-03  7.829909e-03  7.829909e-03  7.829909e-03   \n",
       "std    2.394855e-01  4.990332e-02  8.813970e-02  8.813970e-02  8.813970e-02   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "75%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "max    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "\n",
       "       psychiatric_or_mental_illness          none  \n",
       "count                   1.804874e+06  1.804874e+06  \n",
       "mean                    7.829909e-03  9.159986e-01  \n",
       "std                     8.813970e-02  2.773900e-01  \n",
       "min                     0.000000e+00  0.000000e+00  \n",
       "25%                     0.000000e+00  1.000000e+00  \n",
       "50%                     0.000000e+00  1.000000e+00  \n",
       "75%                     0.000000e+00  1.000000e+00  \n",
       "max                     1.000000e+00  1.000000e+00  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_cols = ['male','female','homosexual_gay_or_lesbian', 'christian', 'jewish', 'muslim', 'black','white', 'psychiatric_or_mental_illness']\n",
    "train['none'] = 1-train[label_cols].max(axis=1)\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1804874, 97320)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train),len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMMENT = 'comment_text'\n",
    "train[COMMENT].fillna(\"unknown\", inplace=True)\n",
    "test[COMMENT].fillna(\"unknown\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF Vectorizer is used to vectorise the comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = train.shape[0]\n",
    "vec = TfidfVectorizer(ngram_range=(1,2), tokenizer=word_tokenize,\n",
    "               min_df=3, max_df=0.9, strip_accents='unicode', use_idf=1,\n",
    "               smooth_idf=1, sublinear_tf=1 )\n",
    "trn_term_doc = vec.fit_transform(train[COMMENT])\n",
    "test_term_doc = vec.transform(test[COMMENT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<1804874x2304861 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 170107570 stored elements in Compressed Sparse Row format>,\n",
       " <97320x2304861 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 9124050 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_term_doc, test_term_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pr(y_i, y):\n",
    "    p = x[y==y_i].sum(0)\n",
    "    return (p+1) / ((y==y_i).sum()+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = trn_term_doc\n",
    "test_x = test_term_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2215173)\t0.10006306272618043\n",
      "  (0, 2212065)\t0.05151512124954903\n",
      "  (0, 2105952)\t0.09996826803093134\n",
      "  (0, 2105940)\t0.06336574570502959\n",
      "  (0, 1996994)\t0.14831466813202215\n",
      "  (0, 1983679)\t0.13983321394374026\n",
      "  (0, 1971172)\t0.04160843146272801\n",
      "  (0, 1798807)\t0.1787242327120229\n",
      "  (0, 1798727)\t0.13399055560130785\n",
      "  (0, 1716339)\t0.19907968714630236\n",
      "  (0, 1716332)\t0.1263121417255389\n",
      "  (0, 1599967)\t0.2434632153655707\n",
      "  (0, 1599775)\t0.10649646500957297\n",
      "  (0, 1506149)\t0.17761794575083575\n",
      "  (0, 1489429)\t0.15217178170363835\n",
      "  (0, 1489353)\t0.126315536287002\n",
      "  (0, 1477275)\t0.08792959116969182\n",
      "  (0, 1475035)\t0.05775955002093855\n",
      "  (0, 1454998)\t0.10702980048215424\n",
      "  (0, 1453821)\t0.11963761528822553\n",
      "  (0, 1433887)\t0.05240820742605657\n",
      "  (0, 1155529)\t0.16509154857066993\n",
      "  (0, 1155471)\t0.14593373993520745\n",
      "  (0, 1129089)\t0.13363479822079352\n",
      "  (0, 1128178)\t0.032696420253560725\n",
      "  :\t:\n",
      "  (97318, 84615)\t0.09412734290309624\n",
      "  (97318, 77325)\t0.0912675136919613\n",
      "  (97318, 62948)\t0.02586068672312247\n",
      "  (97318, 42153)\t0.1233296816251209\n",
      "  (97318, 35662)\t0.11835630667589393\n",
      "  (97318, 35060)\t0.0396641710196386\n",
      "  (97319, 2287307)\t0.16236682134535949\n",
      "  (97319, 1864362)\t0.22756623376797588\n",
      "  (97319, 1864291)\t0.17207795450176996\n",
      "  (97319, 1571131)\t0.3843768478572392\n",
      "  (97319, 1571129)\t0.30058488501025526\n",
      "  (97319, 1176870)\t0.3521500527466681\n",
      "  (97319, 1176831)\t0.21614705349850644\n",
      "  (97319, 1021780)\t0.21355440023533295\n",
      "  (97319, 1021769)\t0.16663071841129676\n",
      "  (97319, 922183)\t0.30696249456462377\n",
      "  (97319, 921909)\t0.16877873932842216\n",
      "  (97319, 878202)\t0.2533734835156666\n",
      "  (97319, 873518)\t0.06057130449124957\n",
      "  (97319, 677119)\t0.20606782504238616\n",
      "  (97319, 528664)\t0.28084810995675547\n",
      "  (97319, 526546)\t0.08981075582111993\n",
      "  (97319, 100164)\t0.03374756613370942\n",
      "  (97319, 74463)\t0.2949291887281603\n",
      "  (97319, 62948)\t0.043994709865433586\n"
     ]
    }
   ],
   "source": [
    "print(test_term_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mdl(y):\n",
    "    y = y.values\n",
    "    r = np.log(pr(1,y) / pr(0,y))\n",
    "    m = LogisticRegression(C=4, dual=True)\n",
    "    x_nb = x.multiply(r)\n",
    "    return m.fit(x_nb, y), r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit male\n",
      "fit female\n",
      "fit homosexual_gay_or_lesbian\n",
      "fit christian\n",
      "fit jewish\n",
      "fit muslim\n",
      "fit black\n",
      "fit white\n",
      "fit psychiatric_or_mental_illness\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "preds = np.zeros((len(test), len(label_cols)))\n",
    "\n",
    "for i, j in enumerate(label_cols):\n",
    "    print('fit', j)\n",
    "    m,r = get_mdl(train[j])\n",
    "    try:\n",
    "        d = open(str(j) + '_model.p', 'wb')\n",
    "        pickle.dump(m, d)\n",
    "    finally:\n",
    "        d.close()\n",
    "    try:\n",
    "        e = open(str(j) + '_r.p','wb')\n",
    "        pickle.dump(r, e)\n",
    "    finally:\n",
    "        e.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    d = open('tf_idf_vectorizer.p', 'wb')\n",
    "    pickle.dump(vec, d)\n",
    "finally:\n",
    "    d.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "\n",
    "vectorizer = pickle.load(open('tf_idf_vectorizer.p','rb'))\n",
    "\n",
    "male_model = pickle.load(open('male_model.p','rb'))\n",
    "male_r = pickle.load(open('male_r.p','rb'))\n",
    "\n",
    "female_model = pickle.load(open('female_model.p','rb'))\n",
    "female_r = pickle.load(open('female_r.p','rb'))\n",
    "\n",
    "homosexual_gay_or_lesbian_model = pickle.load(open('homosexual_gay_or_lesbian_model.p','rb'))\n",
    "homosexual_gay_or_lesbian_r = pickle.load(open('homosexual_gay_or_lesbian_r.p','rb'))\n",
    "\n",
    "christian_model = pickle.load(open('christian_model.p','rb'))\n",
    "christian_r = pickle.load(open('christian_r.p','rb'))\n",
    "\n",
    "jewish_model = pickle.load(open('jewish_model.p','rb'))\n",
    "jewish_r = pickle.load(open('jewish_r.p','rb'))\n",
    "\n",
    "muslim_model = pickle.load(open('muslim_model.p','rb'))\n",
    "muslim_r = pickle.load(open('muslim_r.p','rb'))\n",
    "\n",
    "black_model = pickle.load(open('black_model.p','rb'))\n",
    "black_r = pickle.load(open('black_r.p','rb'))\n",
    "\n",
    "white_model = pickle.load(open('white_model.p','rb'))\n",
    "white_r = pickle.load(open('white_r.p','rb'))\n",
    "\n",
    "psychiatric_or_mental_illness_model = pickle.load(open('psychiatric_or_mental_illness_model.p','rb'))\n",
    "psychiatric_or_mental_illness_r = pickle.load(open('psychiatric_or_mental_illness_r.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cols =  ['male','female','homosexual_gay_or_lesbian', 'christian', 'jewish', 'muslim', 'black','white', 'psychiatric_or_mental_illness']\n",
    "models = {\"male\" : [male_model,male_r],\"female\" : [female_model,female_r],\n",
    "            \"homosexual_gay_or_lesbian\":[homosexual_gay_or_lesbian_model,homosexual_gay_or_lesbian_r],\n",
    "          \"christian\":[christian_model,christian_r],\"jewish\":[jewish_model,jewish_r],\n",
    "            \"muslim\":[muslim_model,muslim_r], \"black\":[black_model,black_r], \"white\":[white_model,white_r],\n",
    "         \"psychiatric_or_mental_illness\":[psychiatric_or_mental_illness_model,psychiatric_or_mental_illness_r]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(name):\n",
    "    return models[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ['i will kill jews']\n",
    "v = vectorizer.transform(text)\n",
    "p = np.zeros((len(text), len(label_cols)))\n",
    "for i, j in enumerate(label_cols):\n",
    "    model = get_model(j)\n",
    "    p[:,i] = model[0].predict_proba(v.multiply(model[1]))[:,1]\n",
    "result = pd.concat([pd.DataFrame(p, columns = label_cols)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       male   female  homosexual_gay_or_lesbian  christian    jewish  \\\n",
      "0  0.998483  0.00006                    0.00106   0.042003  0.998086   \n",
      "\n",
      "     muslim     black     white  psychiatric_or_mental_illness  \n",
      "0  0.990945  0.964633  0.971019                       0.983536  \n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "exposure_count = 0\n",
    "for index, row in result.iterrows():\n",
    "    for col in label_cols:\n",
    "        if(row[col] > 0.1):\n",
    "            exposure_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.67\n"
     ]
    }
   ],
   "source": [
    "score = round(exposure_count/len(label_cols)*100,2)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
